{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Network Monitor Analysis\n",
        "\n",
        "Explore ping and speedtest data from the SQLite databases under `../data/`. The notebook loads every `*.db` file in that folder so you can compare multiple runs, visualize outages, and spot differences between data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import sqlite3\n",
        "import itertools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
        "\n",
        "try:\n",
        "    from scipy import stats  # optional, used for t-tests\n",
        "except ImportError:\n",
        "    stats = None\n",
        "\n",
        "# Locate project root so the notebook works whether launched from repo root or notebooks/\n",
        "PROJECT_ROOT = Path.cwd().resolve()\n",
        "if not (PROJECT_ROOT / \"data\").exists() and (PROJECT_ROOT.parent / \"data\").exists():\n",
        "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
        "\n",
        "DATA_DIR = PROJECT_ROOT / \"data\"\n",
        "DB_PATHS = sorted(DATA_DIR.glob(\"*.db\"))\n",
        "if not DB_PATHS:\n",
        "    raise FileNotFoundError(f\"No SQLite DBs found in {DATA_DIR}. Run the monitor or copy DBs here.\")\n",
        "\n",
        "DB_PATHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_results(db_path: Path) -> pd.DataFrame:\n",
        "    query = \"\"\"\n",
        "        SELECT ts_utc, target_name, interface, host, success, latency_ms, error\n",
        "        FROM results\n",
        "        ORDER BY ts_utc ASC\n",
        "    \"\"\"\n",
        "    with sqlite3.connect(db_path) as conn:\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "    df[\"ts\"] = pd.to_datetime(df[\"ts_utc\"])\n",
        "    df[\"dataset\"] = db_path.stem\n",
        "    return df\n",
        "\n",
        "\n",
        "def load_speedtests(db_path: Path) -> pd.DataFrame:\n",
        "    query = \"\"\"\n",
        "        SELECT ts_utc, tool, success, download_mbps, upload_mbps, ping_ms, error\n",
        "        FROM speedtests\n",
        "        ORDER BY ts_utc ASC\n",
        "    \"\"\"\n",
        "    with sqlite3.connect(db_path) as conn:\n",
        "        df = pd.read_sql_query(query, conn)\n",
        "    df[\"ts\"] = pd.to_datetime(df[\"ts_utc\"])\n",
        "    df[\"dataset\"] = db_path.stem\n",
        "    return df\n",
        "\n",
        "\n",
        "results = pd.concat([load_results(p) for p in DB_PATHS], ignore_index=True)\n",
        "speedtests = pd.concat([load_speedtests(p) for p in DB_PATHS], ignore_index=True)\n",
        "\n",
        "results.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic counts and time ranges per dataset/target\n",
        "overview = (\n",
        "    results.groupby([\"dataset\", \"target_name\"])\n",
        "    .agg(\n",
        "        rows=(\"ts\", \"count\"),\n",
        "        first_ts=(\"ts\", \"min\"),\n",
        "        last_ts=(\"ts\", \"max\"),\n",
        "        failures=(\"success\", lambda s: (s == 0).sum()),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_latency(df: pd.DataFrame, target_filter: str | None = None, dataset_filter: str | None = None):\n",
        "    subset = df.copy()\n",
        "    if target_filter:\n",
        "        subset = subset[subset[\"target_name\"] == target_filter]\n",
        "    if dataset_filter:\n",
        "        subset = subset[subset[\"dataset\"] == dataset_filter]\n",
        "\n",
        "    if subset.empty:\n",
        "        print(\"No data after filtering.\")\n",
        "        return\n",
        "\n",
        "    groups = list(subset.groupby([\"dataset\", \"target_name\"], sort=False))\n",
        "    fig, axes = plt.subplots(len(groups), 1, figsize=(12, 3.0 * len(groups)), sharex=True)\n",
        "    if len(groups) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, ((dataset, target), g) in zip(axes, groups):\n",
        "        g = g.sort_values(\"ts\")\n",
        "        ok = g[g[\"success\"] == 1]\n",
        "        fails = g[g[\"success\"] == 0]\n",
        "\n",
        "        ax.plot(ok[\"ts\"], ok[\"latency_ms\"], label=f\"{dataset} / {target}\")\n",
        "        if not fails.empty:\n",
        "            ax.scatter(fails[\"ts\"], [-5] * len(fails), color=\"red\", marker=\"x\", label=\"fail\")\n",
        "        ax.set_ylabel(\"Latency (ms)\")\n",
        "        ax.legend(loc=\"upper left\")\n",
        "        ax.grid(True)\n",
        "\n",
        "    axes[-1].set_xlabel(\"Time\")\n",
        "    fig.suptitle(\"Ticker-style latency by target (failures marked at -5 ms)\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_latency(results)\n",
        "# Example: plot_latency(results, target_filter=\"gateway\", dataset_filter=\"monitor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outage detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer_interval_seconds(g: pd.DataFrame) -> float | None:\n",
        "    deltas = g[\"ts\"].sort_values().diff().dt.total_seconds().dropna()\n",
        "    return float(deltas.median()) if not deltas.empty else None\n",
        "\n",
        "\n",
        "def find_outages(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for (dataset, target), g in df.sort_values(\"ts\").groupby([\"dataset\", \"target_name\"], sort=False):\n",
        "        cadence = infer_interval_seconds(g) or 0\n",
        "        interface = g[\"interface\"].mode().iat[0] if not g[\"interface\"].dropna().empty else None\n",
        "        in_outage = False\n",
        "        start = end = None\n",
        "        fail_count = 0\n",
        "\n",
        "        for _, row in g.iterrows():\n",
        "            if row[\"success\"] == 0:\n",
        "                if not in_outage:\n", 
        "                    start = row[\"ts\"]\n",
        "                    in_outage = True\n",
        "                    fail_count = 0\n",
        "                fail_count += 1\n",
        "                end = row[\"ts\"]\n",
        "            elif in_outage:\n",
        "                rows.append(\n",
        "                    {\n",
        "                        \"dataset\": dataset,\n",
        "                        \"target_name\": target,\n",
        "                        \"interface\": interface,\n",
        "                        \"start_ts\": start,\n",
        "                        \"end_ts\": end,\n",
        "                        \"duration_seconds\": (end - start).total_seconds() if end and start else None,\n",
        "                        \"failed_checks\": fail_count,\n",
        "                        \"cadence_hint_seconds\": cadence,\n",
        "                    }\n",
        "                )\n",
        "                in_outage = False\n",
        "        if in_outage:\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"dataset\": dataset,\n",
        "                    \"target_name\": target,\n",
        "                    \"interface\": interface,\n",
        "                    \"start_ts\": start,\n",
        "                    \"end_ts\": end,\n",
        "                    \"duration_seconds\": (end - start).total_seconds() if end and start else None,\n",
        "                    \"failed_checks\": fail_count,\n",
        "                    \"cadence_hint_seconds\": cadence,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "outages = find_outages(results)\n",
        "outages.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uptime summary per dataset/target\n",
        "uptime = (\n",
        "    results.assign(is_failure=lambda d: d[\"success\"] == 0)\n",
        "    .groupby([\"dataset\", \"target_name\"], as_index=False)\n",
        "    .agg(total_checks=(\"success\", \"count\"), failures=(\"is_failure\", \"sum\"))\n",
        ")\n",
        "uptime[\"availability_pct\"] = 100 * (1 - uptime[\"failures\"] / uptime[\"total_checks\"].clip(lower=1))\n",
        "uptime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical comparisons between datasets\n",
        "\n",
        "Welch t-tests (if SciPy is installed) plus effect sizes to highlight latency differences across datasets for the same target. Only successful pings are compared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_latency(df: pd.DataFrame, target_name: str) -> pd.DataFrame:\n",
        "    subset = df[(df[\"target_name\"] == target_name) & (df[\"success\"] == 1)].dropna(subset=[\"latency_ms\"])\n",
        "    results_rows = []\n",
        "\n",
        "    for (d1, d2) in itertools.combinations(sorted(subset[\"dataset\"].unique()), 2):\n",
        "        a = subset[subset[\"dataset\"] == d1][\"latency_ms\"].to_numpy()\n",
        "        b = subset[subset[\"dataset\"] == d2][\"latency_ms\"].to_numpy()\n",
        "        if len(a) < 2 or len(b) < 2:\n",
        "            continue\n",
        "\n",
        "        mean_a, mean_b = float(np.mean(a)), float(np.mean(b))\n",
        "        diff = mean_b - mean_a\n",
        "        pooled_std = float(np.sqrt(((a.var(ddof=1) + b.var(ddof=1)) / 2))) if len(a) > 1 and len(b) > 1 else np.nan\n",
        "        cohen_d = diff / pooled_std if pooled_std and not np.isnan(pooled_std) else np.nan\n",
        "\n",
        "        p_value = np.nan\n",
        "        if stats:\n",
        "            t_stat, p_value = stats.ttest_ind(a, b, equal_var=False)\n",
        "\n",
        "        results_rows.append(\n",
        "            {\n",
        "                \"target_name\": target_name,\n",
        "                \"dataset_a\": d1,\n",
        "                \"dataset_b\": d2,\n",
        "                \"mean_a_ms\": mean_a,\n",
        "                \"mean_b_ms\": mean_b,\n",
        "                \"diff_ms\": diff,\n",
        "                \"cohen_d\": cohen_d,\n",
        "                \"p_value_welch\": p_value,\n",
        "                \"n_a\": len(a),\n",
        "                \"n_b\": len(b),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame(results_rows).sort_values(\"diff_ms\")\n",
        "\n",
        "\n",
        "latency_comparisons = {t: compare_latency(results, t) for t in results[\"target_name\"].unique()}\n",
        "latency_comparisons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Speedtests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "speedtests.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_speedtests(df: pd.DataFrame, dataset_filter: str | None = None):\n",
        "    subset = df.copy()\n",
        "    if dataset_filter:\n",
        "        subset = subset[subset[\"dataset\"] == dataset_filter]\n",
        "    if subset.empty:\n",
        "        print(\"No speedtest data.\")\n",
        "        return\n",
        "\n",
        "    subset = subset.sort_values(\"ts\")\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "    axes[0].plot(subset[\"ts\"], subset[\"download_mbps\"], label=\"download\")\n",
        "    axes[0].plot(subset[\"ts\"], subset[\"upload_mbps\"], label=\"upload\")\n",
        "    axes[0].set_ylabel(\"Mbps\")\n",
        "    axes[0].legend(loc=\"upper left\")\n",
        "\n",
        "    axes[1].plot(subset[\"ts\"], subset[\"ping_ms\"], color=\"orange\")\n",
        "    axes[1].set_ylabel(\"Ping (ms)\")\n",
        "\n",
        "    fail_mask = subset[\"success\"] == 0\n",
        "    axes[2].scatter(subset.loc[fail_mask, \"ts\"], [1] * fail_mask.sum(), color=\"red\", marker=\"x\", label=\"failure\")\n",
        "    axes[2].set_ylabel(\"Failures\")\n",
        "    axes[2].set_yticks([])\n",
        "    axes[2].legend(loc=\"upper left\")\n",
        "\n",
        "    axes[-1].set_xlabel(\"Time\")\n",
        "    fig.suptitle(\"Speedtest history\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_speedtests(speedtests)\n",
        "# Example: plot_speedtests(speedtests, dataset_filter=\"monitor\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
